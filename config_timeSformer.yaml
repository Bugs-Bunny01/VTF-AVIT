# Transformer architecture specification

use_gpu: 1 
num_workers: 16
batch_size: 8
lr: 5e-5

#Training Data Dir
Train_data_dir: D:\dl\slip_dataset\WholeDataset\training
#Valid_data_dir
Valid_data_dir: D:\dl\slip_dataset\WholeDataset\testing
#Test Data Dir
Test_data_dir: D:\dl\slip_dataset\WholeDataset\testing

#Data processing parameters
Fruit_type: ['other']
label_encoding : {'other':'6'}
Tactile_Image_width: 640  # Raw Image width (for slip detection dataset)
Tactile_Image_height: 480 # Raw Image Height (for slip detection dataset)
Tactile_scale_ratio: 0.25
Visual_Image_width: 640
Visual_Image_height: 480
Visual_scale_ratio: 0.25 #Raw image size (480, 640) -> resized image (480 * scale_ratio, 640 * scale_ratio)
#scale_ratio: 0.25  #Raw image size (480, 640) -> resized image (480 * scale_ratio, 640 * scale_ratio)
video_length: 8

# Model options: vivit_fdp_two_fruit, timeSformer_orig_two_fruit, basic_CNN
Model_name: timeSformer_orig_two
Modality: Combined # Three options, Combined, Tactile, Visual
base_network: vgg_19 # only used for the basic_CNN architecture, there are some other options
# vgg_19; inception_v3; alexnet(debug)


#Training Parameters
attn_drop: 0.20  # timeSformer_orig_two
mlp_drop: 0.20 # timeSformer_orig_two
CNN_drop: 0.2 # used for basic_CNN
LSTM_drop: 0.2 # used for basic_CNN
pretrained: True # used for basic_CNN, load pretrained model or not.
frozen_weights: False # used for basic_CNN, CNN parameters are trainable or not
epochs: 200
print_interval: 1
save_dir: ./Trained_Model
use_random_seed: 0  #Set to 1 to use random seed. Otherwise, seed below is used for reproducibility
seed: 42 #Only used if use_random_seed = 1
skip_init_in_train: 1
test_eval: 1
pretrained1: 0
pretrained_path: ./Trained_Model/timeSformer_orig_two/v4t*/timeSformer_orig_two_00129.pt