# Transformer architecture specification

use_gpu: 1 
num_workers: 4
batch_size: 1
lr: 5e-5

#Training Data Dir
Train_data_dir: D:\dl\slip_dataset\Whole Dataset\training
#Test Data Dir
Test_data_dir: D:\dl\slip_dataset\Whole Dataset\testing
#  D:\dl\test

#Data processing parameters
Fruit_type: ['other']    #['apple', 'kiwi', 'lemon', 'orange', 'plum', 'tomato', 'other']
label_encoding : {'other':'6'}  #{'apple':'0', 'kiwi':'1', 'lemon':'2', 'orange':'3', 'plum':'4', 'tomato':'5','other':'6'}
Tactile_Image_width: 640  # Raw Image width (for slip detection dataset)
Tactile_Image_height: 480 # Raw Image Height (for slip detection dataset)
Tactile_scale_ratio: 0.25
Visual_Image_width: 640
Visual_Image_height: 480
Visual_scale_ratio: 0.25  #Raw image size (480, 640) -> resized image (480 * scale_ratio, 640 * scale_ratio)
#scale_ratio: 0.25  #Raw image size (480, 640) -> resized image (480 * scale_ratio, 640 * scale_ratio)
video_length: 8

# Model options: vivit_fdp_two_fruit, timeSformer_orig_two_fruit, basic_CNN
Model_name: timeSformer_orig_two
Modality: Combined # Three options, Combined, Tactile, Visual
base_network: vgg_19 # only used for the basic_CNN architecture, there are some other options
# vgg_19; inception_v3; alexnet(debug)


#Training Parameters
attn_drop: 0.0  # timeSformer_orig_two
mlp_drop: 0.0 # timeSformer_orig_two
CNN_drop: 0.2 # used for basic_CNN
LSTM_drop: 0.2 # used for basic_CNN
pretrained: False # used for basic_CNN, load pretrained model or not.
frozen_weights: False # used for basic_CNN, CNN parameters are trainable or not
epochs: 200
print_interval: 1
save_dir: ./Trained_Model
use_random_seed: 0  #Set to 1 to use random seed. Otherwise, seed below is used for reproducibility
seed: 42 #Only used if use_random_seed = 1
skip_init_in_train: 1
test_eval: 1
pretrained1: 0
pretrained_path: D:/dl/software_check/timesformer/timeSformer_orig_two_last.pt
model_trained: 1
model_trained_path: Trained_Model/timeSformer_orig_two/14_07_2023__21_27_00/timeSformer_orig_two_last.pt