# Transformer architecture specification

use_gpu: 1 
num_workers: 4
batch_size: 2
lr: 5e-5  #learn percent

#Training Data Dir
Train_data_dir: C:\Users\17664\Desktop\game
#Valid Data Dir
#Valid_data_dir: D:\desk\Fruit_dataset
#Testing Data Dir
#Test_data_dir: D:\desk\test


#Data processing parameters
Fruit_type: ['apple']
label_encoding : {'apple':'0'}
Tactile_Image_width: 200  # Raw Image width (for slip detection dataset)
Tactile_Image_height: 150 # Raw Image Height (for slip detection dataset)
Tactile_scale_ratio: 1
Visual_Image_width: 640
Visual_Image_height: 480
Visual_scale_ratio: 0.25  #Raw image size (480, 640) -> resized image (480 * scale_ratio, 640 * scale_ratio)
#scale_ratio: 0.25  #Raw image size (480, 640) -> resized image (480 * scale_ratio, 640 * scale_ratio)
video_length: 8

# Model options: vivit_fdp_two_fruit, timeSformer_orig_two_fruit, basic_CNN
Model_name: vivit_fdp_two
Modality: Combined # Three options, Combined, Tactile, Visual
base_network: vgg_19 # only used for the basic_CNN architecture, there are some other options
# vgg_19; inception_v3; alexnet(debug)


#Training Parameters

attn_drop: 0.2  # used for Transformer models
mlp_drop: 0.2 # used for Transformer models
CNN_drop: 0.2 # used for basic_CNN
LSTM_drop: 0.2 # used for basic_CNN
pretrained: False # used for basic_CNN, load pretrained model or not.
frozen_weights: False # used for basic_CNN, CNN parameters are trainable or not
epochs: 20
print_interval: 1
save_dir: ./Trained_Model

use_random_seed: 0  #Set to 1 to use random seed. Otherwise, seed below is used for reproducibility
seed: 42 #Only used if use_random_seed = 0

skip_init_in_train: 1   #if=0,initialize weights
test_eval: 1
pretrained: 0
pretrained_path: None
